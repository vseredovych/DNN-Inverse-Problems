% ============================================ %

\documentclass[14pt,a4paper]{extarticle}
%\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[ukrainian]{babel}


\usepackage{amssymb}
\usepackage{physics}
\usepackage{amsmath}
% \operatorname*{argmin}_\theta f(x)
% \operatorname*{arg\,max}_\theta f(x)



\usepackage[active]{srcltx}
\usepackage[final]{pdfpages}

\usepackage[hidelinks]{hyperref}

\usepackage{verbatim}

% ============================================ %

%\pagestyle{empty}                     %нумерацiя сторiнок i т.д.
\pagestyle{headings}                   %нумерацiя сторiнок вгорi зправа i т.д.
%\renewcommand{\baselinestretch}{1.5}   %мiжстрiчковий інтервал
%\parindent=7.5mm                      %абзацний відступ
\righthyphenmin=2                     %перенос 2 останніх букв
\pagenumbering{arabic}
\tolerance=400
\mathsurround=2pt
\hfuzz=1.5pt

% ============================================ %

\hoffset=-0.5cm        %+2.5cm -- вiдступ вiд лiвого краю
\voffset=-1.5cm        %+2.5cm -- вiдступ зверху
\oddsidemargin=0.1cm   %ліве поле
\topmargin=0.1cm       %верхнє поле
\headheight=0.5cm      %висота верхнього колонтитулу
\footskip=1cm          %висота нижнього колонтитулу
\headsep=0.3cm         %відступ від колонт. до тексту
\textwidth=17cm        %ширина сторінки
\textheight=25.5cm     %висота сторінки

% ============================================ %
	
\newcounter{e}
\setcounter{e}{0}
\newcommand{\n}{\refstepcounter{e} (\arabic{e})}

\newcounter{pic}
\setcounter{pic}{0}
\newcommand{\pic}[1]{\refstepcounter{pic} \vspace{-0.3cm}\textit{Рисунок \arabic{pic}\label{#1}.}}

\newcounter{tabl}
\setcounter{tabl}{0}
\newcommand{\tabl}[1]{\refstepcounter{tabl} \vspace{-0.3cm}\textit{Таблиця \arabic{tabl}\label{#1}.}}

\newcounter{dod}
\setcounter{dod}{0}
\newcommand{\dod}[1]{\refstepcounter{dod} \textit{Додаток \arabic{dod}\label{#1}.}}


\newtheorem{theorem}{Теорема}[section]
\newtheorem{defn}[theorem]{Означення}
\newtheorem{lemma}[theorem]{Лема}

\newcommand{\proof}{\textit{Доведення. \space}}
% \setcounter{page}{1}
% \setcounter{section}{1}

\numberwithin{equation}{section}
\numberwithin{figure}{section}

% \newcommand{\unknownx}{	\boldsymbol{$1}^{\star}}
% \newcommand{\bt}[1]{\textbf{#1}}

% ============================================ %
	
% bibliography
\usepackage[
	backend=biber,
	style=numeric,
	sorting=none
]{biblatex}
\addbibresource{resources/bibliography.bibtex}

% ============================================ %

\begin{document}
	% ============================================ %
	\begin{titlepage}%
		\begin{center}
			{\textbf{ЛЬВІВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ \\ ІМЕНІ ІВАНА ФРАНКА}}\par
			{Факультет прикладної математики та інформатики \\ Кафедра обчислювальної математики}\par
			\begin{center}
				
			\end{center}
			\vspace{25mm}
			{\textbf{\huge{Курсова робота}}}\par
			\vspace{5mm}
			{\large{Використання глибокого навчання для обернених задач}}\par
			\vspace{5mm}
			{}\par %subtitle
		\end{center}
		
		\vfill
		\vskip80pt
		
		\begin{flushleft}
			\hskip 8cm 
			Виконав студент IV курсу групи
			\\ \hskip8cm
			ПМп-41 напрямку підготовки 
			\\ \hskip8cm
			(спеціальності)
			\\ \hskip8cm
			113 -- ``Прикладна математика''
			\\ \hskip8cm
			Середович В.B.
		\end{flushleft}
		\begin{flushleft}
			\hskip8cm 
			Курівник: Музичук Ю.А
		\end{flushleft}
		
		\vfill
		
		\begin{center}
			\large
			Львів - 2020
		\end{center}
	\end{titlepage}

	% ============================================ %
	% Зміст
	\addtocontents{toc}{\protect\thispagestyle{empty}}
	\tableofcontents

	% ============================================ %
	% Вступ
	
	\newpage
	\thispagestyle{empty}
	\addcontentsline{toc}{section}{Вступ}
	\section*{Вступ}
	
	Вступ про типи обернені задач та глибоке навчання
	\\
	
	Оберненими задачами називають такі задачі, коли необхідно відновити параметри які характеризують деяку модель з використанням непрямих спостережень. До них можна віднести багото по відновленню зображень зменшення кількості шуму (deblurring) чи заповнення втрачених даних (inpainting).

	\begin{comment}
	"""
	http://repository.dnu.dp.ua:1100/upload/ddcba97cf65d7af08acc8b934080e148.pdf
	
	1) визначати механічні та теплофізичні властивості матеріалів, ідентифікув ати полімерні і композитні матеріали, біоматеріали, п'єзокерам ічні матеріали;
	2) розв’язувати задачі сейсморозвідки , а саме визначати розташування й
	потужності покладів корисних копалин за відбитими від родовища звуковими сиг
	налами;
	3) розв’язувати проблеми неруйнівного контролю, а саме визначати розташування й конфігурацію дефекту за виміряним на поверхні тіла полем пружних
	переміщень або за резонансними частотами;
	4) моделювати явища акустичної емісії та встановлювати зв'язок між осн ов
	ними характеристиками емісії та хар актеристиками напруженого стану, д ослід
	ження цього явища дозволяє виявити стан конструкції, що передує її руйнуванню;
	5) розв’язувати задачі рентгенівської й акустичної томографії.
	Вибираючи математичну модель, звичайно фіксують два етапи:
	1) вибір структури оператора A, що здійснює відображення входу xt на
	вихід yt;
	""'"
	content...
	\end{comment}


	% ============================================ %
	
	\newpage
	\thispagestyle{empty}
	\section{Постановка задачі} 
	
	
	\begin{comment}
	"""
	Відповідно до поняття, уведеного на початку століття Ж. Адамаром, задачу
	z  Ru називають коректно поставленою, якщо вона задовольняє тр и умови:
	1) за кожного u U розв'язок задачі існує;
	2) розв'язок є єдиний за кожного u U ;
	3) розв'язок є стійкий до малих варіацій величини u , тобто достатньо малим
	зміненням величини u відповідають як завгодно малі зміни величини z [1, 7].
	Якщо задача не задовольняє хоча б одну із зазначених умов, то її називають некоректно поставленою.
	Очевидно тепер, що обернені задачі в розглянутих прикладах відносять до
	числа некоректно поставлених, оскільки в них порушується третя, а мо жливо, і
	перша із зазначених вище умов. Некоректність постановки обернен ої задачі і є її
	математична особливість. Якщо для пошуку наближеного розв’язку оберненої з адачі застосовувати будь-який класичний алгоритм формально, не враховуючи н екоректність постановки задачі, то є великий ризик отримати результат, який не
	має ні наукової, ні прикладної цінності.
	"""
	\end{comment}
	
	
	
	
	Оберненими задачами будемо вважати такі задачі, в яких невідомим є $n-$ піксельне зображення $\boldsymbol{x} \in \mathbb{R}^{n}$ яке було отримане з $m$ вимірювань $\boldsymbol{y} \in \mathbb{R}^{m}$ відповідно до рівняння
	\begin{equation}
	\label{forward-problem}
	\boldsymbol{y}=\mathcal{A}\left(\boldsymbol{x}\right)+\boldsymbol{\varepsilon}
	\end{equation}
	де $\mathcal{A}$ - це прямий оператор вимірювання та $\boldsymbol{\varepsilon}$ є певним вектором шуму. Метою задачі є відновлення $x$ з $y$. Можна розглянути більш загальний випадок моделі неадитивного шуму, який має вигляд 
	\begin{equation}
	\label{forward-problem-non-additive}
	\boldsymbol{y}=\mathcal{N}\left(\mathcal{A}\left(\boldsymbol{x}\right)\right)
	\end{equation}
	де $\mathcal{N}(\cdot)$ є прикладами вибірки з шумом.


	\begin{defn}
		\label{well-posed}
		Відповідно до поняття, уведеного Жаком Адамаром, задачу \ref{forward-problem-non-additive} називають коректно поставленою, якщо вона задовольняє наступні умови: 
		\begin{enumerate}
			\item Для кожного $x$ розв'язок задачі існує.
			\item Розв'язок є єдиний для кожного $x$.
			\item Розв'язок є стійкий до малих варіацій величини $x$, тобто достатньо малим зміненням величини $x$ відповідають як завгодно малі зміни величини $y$.
		\end{enumerate}
	\end{defn}

	\begin{defn}
		\label{ill-posed}	
		Задачу, яка не задовільняє хоча б одну із умов означення \ref{well-posed}, називають некоректно поставленою.
	\end{defn}

	Отже, очевидно, що розглянута обернена задача є некоректно (або погано обумовленою), оскільки в ній порушуються умови означення \ref{well-posed}. Така задача знаходження єдиного розв'язку, яка задовілняє спостереженням є складною або неможливою, за умови відсутності попередніх знаннь про дані.

	Таку задачу оцінки $\boldsymbol{x}$ з $\boldsymbol{y}$ називають задачею реконструкції зображенні. Класичні підподи до реконструкції зображеннь припускають наявність деякої попередньої інформації про зображення, яку називають пріором. В якості пріору можуть виступати параметри гладкості, щільності та інші геометричні властивості зображення.

	%TODO
	Отже метою даної роботи буде розв'язання таких обернених задач за допомогую глибокого навчання. Зокрема, будемо розглядати задачу зменшення кількості шуму у зобреженнях.

	%	Метою даної роботи є дослідження ефективності різних методів атак на лінійні моделі машинного навчання, та аналіз можливих методів захисту від них.
		
	%	Виходячи з мети, визначеними завданнями роботи є:
	%	\begin{itemize}
	%		\item Реалізувати лінійну модель машинного навчання
	%		\item Розглянути різні методи генерування змагальних прикладів
	%		\item Застосувати атаки на створену модель та проаналізувати їх ефективність
	%		\item Розглянути можливі методи захисту від атак
	%	\end{itemize}
		
	% ============================================ %
	\newpage
	\thispagestyle{empty}
	\section{Структура обернених задач}

	%\subsection{Розв'язування обернених задач}
	
	Якщо розподіл шуму відомий, $x$ можна відновити розвязавши задачу оцінки максимальної ймовірності (maximum likelihood):
	$$
	\hat{\boldsymbol{x}}_{\mathrm{ML}}
	=\underset{\boldsymbol{x}}{\arg \max{ p (\boldsymbol{y} \mid \boldsymbol{x}) }}
	=\underset{\boldsymbol{x}}{\arg \min }-\log p(\boldsymbol{y} \mid \boldsymbol{x})
	$$
	де $p(\boldsymbol{y} \mid \boldsymbol{x})$ це ймовірність спостереження $\boldsymbol{y}$ за умови якщо $\boldsymbol{x}$ є справжнім зображенням.
	
	В залежності від умов задачі, можуть бути відомі попередні дані про те яким має бути $x$. Ці умови можуть бути використанні для формування  задачі оцінки максимальної апостеріорної ймовірності (maximum a posteriori), що приводить до задачі
	$$
	\hat{\boldsymbol{x}}_{\mathrm{MAP}}
	=\underset{\boldsymbol{x}}{\arg \max{ p(\boldsymbol{x} \mid \boldsymbol{y}) }}
	=\underset{\boldsymbol{x}}{\arg -\max{ p(\boldsymbol{y} \mid \boldsymbol{x})} } p(\boldsymbol{x})
	=\underset{\boldsymbol{x}}{\arg \min }-\ln p(\boldsymbol{y} \mid \boldsymbol{x})-\ln p(\boldsymbol{x})
	$$
	Для випадку білого гаусівського шуму, формулювання MAP дає:
	\begin{equation}
	\label{MAP-avgn}
	 \frac{1}{2}\|\mathcal{A}(\boldsymbol{x})-\boldsymbol{y}\|_{2}^{2}+r(\boldsymbol{x})
	\end{equation}
	де  $r(\boldsymbol{x})$ є пропорційним до негативного логарифмічного пріора $\boldsymbol{x} .$. Прикладами такого підходу є регуляризація Тіхонова. 
	
	
	\begin{comment}
	Його метод оснований на залучені додаткової
	інформації про розв’язок, яка може бути як якісною так і кількісною.

	Наприклад, можна шукати розв’язок максимально близький до деякого
	профілю, тобто, до декого вектора $y$.	
	[0
	. Концепція регуляризації зводиться до
	заміни початкової некоректної задачі на задачу про мінімізацію наступної
	функції: 0 W([,l) = A[ - B + l [ -[ , де l - малий додатній параметр
	регуляризації, який необхідно підібрати певним способом. Якщо розглядати
	не дискретну, а неперервну задачу, тоді W([,l), буде представляти собою не
	функцію, а функціонал, який має назву функціонал Тіхонова.
	%$$
	%\underset{x \in \mathbb{R}^{n}}{\min }
	%\left\{\|Ax-b\|_{2}^{2}+ \lambda \|x\|_{2}^{2}\right\}
	%$$
	\end{comment}

	Задача маскимальної апостеріорної оцінки може використовуватись для реконструкції зображень, однак такий такий підхід може бути не таким ефективним, якщо розподіл шуму або прямий оператор є невідомі. 
	Алгоритми основані на використанні машинного навчання дають змогу побороти більшість з цих труднощів, що робить їх ефективною альтернативою класичному підходу.

	\section{Огляд машинного навчання для розв'язування обернених задач}

	\subsection{Кортрольоване і некортнольоване навчання}
	Перший і найпоширеніший тип розв'язування оберених задач з викорисатнням глибогоко навчання є контрольована інверсія. Ідея полягає у створенні співвідношення між датасетом справжніх зображень $x$ та відповідними вимірюваннями $y$. Тобто ми можемо натренувати нейронну мережу приймати значення $y$ та реконстроювати оберенне значення $x$. Цей підхід є дуже ефективним, але є чутливим до змін в опереторі вимірювання $A$. 
	
	Другим типом розв'язування обернених задач є неконтрольованого навчання. Він передбачає, що інформація про пари вхідної та вихідної інформації $x$ та $y$ невідомі під час тренування. До нього можна віднести ситуації коли відомі тільки чисті зображення $x$ або тільки результати вимірювання $y$.

	Ці два підходи маюсь фундоментальні відміності і ця робота націлена саме на методи контрольованого навчання, тому що очікується що вони дадуть кращі результати в порівнянні з класичними методами. 
	
	\subsection{Класифікація навчання розв'язування обернених задач}
	
	% ============================================ %
	\newpage
	\thispagestyle{empty}
	\section{Глибоке навчання для обернених задач}
	
	\subsection{Автоенкодер}
	TODO

	\subsection{Алгоритм 2}
	TODO


	% ============================================ %
	\newpage
	\thispagestyle{empty}
	\section{Реалізація та аналіз}
	
	\section{Герерація шуму}
	TODO
	
	\subsection{Реалізація}
	TODO

	\subsection{Аналіз}
	TODO
	
	% ============================================ %		
	\newpage
	\thispagestyle{empty}
	\section{Висновок}
	TODO
	
	%============================================ %
	\newpage
	\thispagestyle{empty}
	
	% Deep Learning Techniques for Inverse Problems in Imaging
	\nocite{ongie2020deep}
		
	% Solving ill-posed inverse problems using iterative deep neural networks
	\nocite{Adler_2017}
	\printbibliography[title={Бібліографія}]
	% ============================================ %
\end{document}