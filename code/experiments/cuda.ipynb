{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, jit, vectorize\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import void, uint8 , uint32, uint64, int32, int64, float32, float64, f8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple cuda algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05702106 0.79560147 0.48281886 0.02902985 0.04606159 0.19667842\n",
      " 0.96377143 0.88879281 0.7063751  0.16971963]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05695934, 0.66157056, 0.4484983 , 0.0290217 , 0.04602904,\n",
       "       0.19418106, 0.7459544 , 0.71079697, 0.60839872, 0.16810861])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "@cuda.jit\n",
    "def tanh(a):\n",
    "    # Thread id\n",
    "    tx = cuda.threadIdx.x\n",
    "    # Block id\n",
    "    ty = cuda.blockIdx.x\n",
    "    # Block size\n",
    "    bw = cuda.blockDim.x\n",
    "    # THe actual id of thread on the grid\n",
    "    pos = tx + ty * bw\n",
    "    a[pos] = math.tanh(a[pos])\n",
    "\n",
    "a = np.random.rand(10)\n",
    "print(a)\n",
    "\n",
    "tanh[32, 10](a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms with reduce operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Build-in reduce\n",
    "- https://numba.pydata.org/numba-doc/dev/cuda/reduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761995.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.reduce\n",
    "def sum_reduce(a, b):\n",
    "    return a + b\n",
    "\n",
    "A = (numpy.arange(1234, dtype=numpy.float64)) + 1\n",
    "expect = A.sum()      # numpy sum reduction\n",
    "got = sum_reduce(A)   # cuda sum reduction\n",
    "print(got)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own reduce with cuda\n",
    "- https://people.duke.edu/~ccc14/sta-663/CUDAPython.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  [ 4  7 13  0 18  1 20 18  1  8 17 21 10  0  2 10 19  9 15 12  6  5 16 21]\n",
      "a.sum():  253\n",
      "Block dim:  (6, 1)\n",
      "Grid dim:  (6, 1)\n",
      "[43 85 50 75 18  1 20 18  1  8 17 21 10  0  2 10 19  9 15 12  6  5 16 21]\n",
      "Partial sum:  [43 85 50 75]\n",
      "[253  85  50  75  18   1  20  18   1   8  17  21  10   0   2  10  19   9\n",
      "  15  12   6   5  16  21]\n",
      "Sum:  253\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit('int32(int32, int32)', device=True)\n",
    "def sum_device(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def max_device(a, b):\n",
    "    return a if a > b else b\n",
    "\n",
    "@cuda.jit('void(int32[:], int32[:])')\n",
    "def sum_reduce(a, b):\n",
    "    \"Simple implementation of reduction kernel\"\n",
    "    # Allocate static shared memory of 512 (max number of threads per block for CC < 3.0)\n",
    "    # This limits the maximum block size to 512.\n",
    "    tx = cuda.threadIdx.x\n",
    "    bx = cuda.blockIdx.x\n",
    "    bw = cuda.blockDim.x\n",
    "    sa = cuda.shared.array(shape=(512,), dtype=int32)\n",
    "\n",
    "    i = tx + bx * bw\n",
    "\n",
    "    sa[tx] = a[i]\n",
    "    if tx == 0:\n",
    "        s = sa[tx]\n",
    "        cuda.syncthreads()\n",
    "        for j in range(1, bw):\n",
    "            s = sum_device(s, sa[j])\n",
    "        b[bx] = s\n",
    "\n",
    "# numbers to be added in the partial sum (must be less than or equal to 512)\n",
    "# total length of vector to be summed\n",
    "k = 4\n",
    "n = 6*4 \n",
    "\n",
    "a = np.random.randint(0, n, n).astype(np.int32)\n",
    "print('a: ', a)\n",
    "print('a.sum(): ', a.sum())\n",
    "\n",
    "griddim = (k, 1)\n",
    "blockdim = (a.size//k, 1)\n",
    "print(\"Block dim: \", blockdim)\n",
    "print(\"Grid dim: \", blockdim)\n",
    "\n",
    "\n",
    "sum_reduce[griddim, blockdim](a, a)\n",
    "print(a)\n",
    "print(\"Partial sum: \", a[:k])\n",
    "sum_reduce[1, griddim](a[:k], a)\n",
    "print(a)\n",
    "print(\"Sum: \", a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ code examples\n",
    "- https://sodocumentation.net/cuda/topic/6566/parallel-reduction--e-g--how-to-sum-an-array-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jit \n",
    "- https://numba.pydata.org/numba-doc/latest/cuda/ufunc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47867677 0.38808894 0.4059148  ... 0.2861206  0.34186673 0.30056685]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from numba import vectorize, cuda\n",
    "import numpy as np\n",
    "\n",
    "@vectorize(['float32(float32)',\n",
    "           'float32(float32)'],\n",
    "           target='cuda')\n",
    "def sigmoid(a):\n",
    "    return 1/(1 + np.e ** a)\n",
    "#  math.sqrt(b ** 2 - 4 * a * c)\n",
    "\n",
    "N = 10000\n",
    "dtype = np.float32\n",
    "\n",
    "# prepare the input\n",
    "A = np.array(np.random.rand(N), dtype=dtype)\n",
    "\n",
    "sigma = sigmoid(A)\n",
    "\n",
    "print(sigma)  # print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
