
––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Постановка задачі

Оберненими називаюсть такі задачі в яких необхідно відновити дані про деякий процес на основі непрямих спостережень. Зазвичай такі задачі є некоректними, адже вони можуь не мати єдиного розв’язку.

Сформулюємо загальну постановку задачі у вигляді (1). Тобто, ми прагнемо відновити зображення “x” отримане в результаті деякого оперетора вимірювання A, та вектору шуму еплисон.

В контексті цієї роботи будемо розглядати задачу по видаленню шуму із пошкоджених зображень. 

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Структура обернених задач

Для цього, cформулюємо задачу максимальної ймовірносі (2), де ми прагнемо максимізувати ймовірність спостереження вімірювань “y” за умови що ”x” є cправжнім зображенням. 

В залежності від умов задачі, нам можуть бути відомі попередні дані про те яким має бути це “x” які можна використати для формулювання задачі максимальної апостеріорної оцінки (3).

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Регуляризація

Для випадку нормального розподілу шуму задача реконструкції “x” зводиться до вигляду (4), де R є членом регуляризації а lambda її параметром. Класичним підходом до розв’язання такої некоректної задачі є регуляризація Тіхонова, яку ми будемо використовувати далі.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Автоенкодер

Для розв’язання оберненої задачі методами глибокого навчання будемо використовувати автоенкодер. Автоенкодером називають нейрону мережу яка навчається копiювати свої вхiднi данi у вихiднi. Таку нейронну мережу можна подати у складi двох частин. Функцiя енкодер закодовує свої вхідні дані, тобто оригінальне зображення у так званий “код” та зменшує їх розмірність. Декодер в свою чергу, вiдтворє з цього коду початкове зображення. Таку мережу тренують щоб вивчити основні властивості зображення та зробити з неї функцію тотожнього відображенням.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Автоенкодер для видалення шуму

На основі звичайного автоенкодера можна побудувати нейронну мережу для розв’язування обернених задач, таких як видалення шуму із зображень. Відмінність її полягає в тому що для такої мережі на вхід подаються пошкоджені дані і на їх основі автоенкодер навчається мінімізувати функцію втрат при реконструкції зображень. Для генерації пошкоджень оригінальних зразків був використовувався білий шум Гауса.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Оцінка реконструкції

Для побудови такої моделі нейроної мережі, була використана штрафна функція  середньо квадратичної похибки, яка задана формулою (5). Для функції втрат при реконструкції зображення використовувалась норма в просторі L2. Мінімізацію штрафної функції проводили алгоритмом градієнтного спуску.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Оцінка зображень
Для того щоб оцінити ефективність реконструкції, була використана ще одна метрика задана формулою (7), яка опирається на рiзницю в структурi всього зображення, а не окремих пiкселiв, що робить її більш об’єктивною метрикою

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Архітектура моделі для автоенкодера

Таким чином, для автоенкодера була побудована модель задана таблицею 1. Як можна бачити, для енкодера використовувалиь два приховані шара, а для декодера один. 

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Тренування моделі
На основі описаної архітектури, були натренованi п’ять моделей для рiзних значень стандартного вiдхилення бiлого шуму Гауса. На графіку (3) наведена ефективність відтворення шуму від ітерації тренування. Як можна бачити iснує чiтка залежнiсть мiж рiвнем шуму доданим до чистих зображень та ефективнiстю його вiдтворення автоенкодером. Для порівняння також був розглянутий випадок коли шум не додавався, тобто стандартне відхилення = 0

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Результат роботи для видалення шуму
Тепер розглянемо результат для реконструкції зображень від шуму. Очевидно, що при збiльшеннi кiлькостi шуму, вiдтвореннi зображення стають меш чіткими та менш схожими на оригiнал. 
Однак, можна сказати, що навiть при дуже значнiй кiлькостi шуму як при σ = 1, вiдтворене зображення все одно залишається читабельним, на вiдмiну вiд пошкодженого варiанту.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Порівняння роботи автоенкодера з регуляризацією
Тепер порівняємо роботу з класичною регуляризацією.  Як можна бачити на зображені (5)
метод регуляризацiї суттєво покращив середньоквадратичну похибку, але загалом зображення залишилось сильно пошкодженим. З iншого боку, зображення, вiдновленнi за допомогою глибокої нейронної мережi, демонструють непоганi результати для обох наведених метрик і візуально теж є досить чітким, що свідчить про ефективність цього мутоду, при достатній кількості тренувальний прикладів.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––
Висновок
Таким чином на основі експерементів можна сказати що побудована модель глибокого навчання є ефективною у розв’язанні розглянутої оберненої задачі. Вона успішно впоралась з видаленням шуму при його низьких показниках та дала непогані результати для його високої  кількості. Окрім, того  автоенкодер продемонстрував себе значно краще в порівнянні з методом регуляризації, з чого можна зробити висновок що глибокого навчання є ефективним підходом до розв'язання поставленої обернених задачі.
